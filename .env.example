# AI Documentation Vector DB - Environment Variables Template
# Copy this file to .env and replace the placeholder values with your actual API keys

# ========== Core API Keys ==========

# OpenAI API Key (required for OpenAI embeddings)
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Firecrawl API Key (optional, for premium web scraping features)
# Get your key at: https://www.firecrawl.dev/
FIRECRAWL_API_KEY=fc-your-firecrawl-api-key-here

# Qdrant API Key (optional, for Qdrant Cloud)
# Leave empty for local Qdrant instance
QDRANT_API_KEY=

# ========== Service URLs ==========

# Qdrant Vector Database URL
# Default: http://localhost:6333 (local Docker instance)
QDRANT_URL=http://localhost:6333

# Redis/DragonflyDB Cache URL
# Default: redis://localhost:6379 (local DragonflyDB instance)
REDIS_URL=redis://localhost:6379

# ========== FastMCP Streaming Configuration ==========
# These settings optimize MCP server performance for large search results

# Transport type: streamable-http (optimal) or stdio (Claude Desktop)
FASTMCP_TRANSPORT=streamable-http

# Host for HTTP transport (only used with streamable-http)
FASTMCP_HOST=127.0.0.1

# Port for HTTP transport (only used with streamable-http)
FASTMCP_PORT=8000

# Response buffer size in bytes (default: 8192)
# Increase for better performance with large results
FASTMCP_BUFFER_SIZE=8192

# Maximum response size in bytes (default: 10485760 = 10MB)
# Increase if working with very large search results
FASTMCP_MAX_RESPONSE_SIZE=10485760

# ========== Unified Configuration (AI_DOCS__ prefix) ==========
# These use the AI_DOCS__ prefix for nested configuration

# Application Settings
AI_DOCS__ENVIRONMENT=development              # development, testing, production
AI_DOCS__DEBUG=false                          # Enable debug mode
AI_DOCS__LOG_LEVEL=INFO                       # DEBUG, INFO, WARNING, ERROR, CRITICAL

# Provider Selection
AI_DOCS__EMBEDDING_PROVIDER=fastembed         # fastembed (local) or openai (cloud)
AI_DOCS__CRAWL_PROVIDER=crawl4ai              # crawl4ai (fast) or firecrawl (premium)

# Performance Tuning
AI_DOCS__PERFORMANCE__MAX_CONCURRENT_CRAWLS=10
AI_DOCS__PERFORMANCE__MAX_CONCURRENT_EMBEDDINGS=32
AI_DOCS__PERFORMANCE__REQUEST_TIMEOUT=30
AI_DOCS__PERFORMANCE__MAX_MEMORY_USAGE_MB=1000

# Cache Configuration
AI_DOCS__CACHE__ENABLE_CACHING=true
AI_DOCS__CACHE__ENABLE_LOCAL_CACHE=true       # In-memory caching
AI_DOCS__CACHE__ENABLE_REDIS_CACHE=true       # DragonflyDB caching
AI_DOCS__CACHE__REDIS_URL=redis://localhost:6379
AI_DOCS__CACHE__TTL_EMBEDDINGS=86400          # 24 hours
AI_DOCS__CACHE__TTL_CRAWL=3600                # 1 hour
AI_DOCS__CACHE__TTL_QUERIES=7200              # 2 hours
AI_DOCS__CACHE__TTL_HYDE=14400                # 4 hours

# OpenAI Settings (when using OpenAI provider)
AI_DOCS__OPENAI__API_KEY=sk-your-openai-api-key-here
AI_DOCS__OPENAI__EMBEDDING_MODEL=text-embedding-3-small
AI_DOCS__OPENAI__DIMENSIONS=1536
# AI_DOCS__OPENAI__API_BASE=https://api.openai.com/v1  # Optional custom endpoint

# Qdrant Settings
AI_DOCS__QDRANT__URL=http://localhost:6333
AI_DOCS__QDRANT__API_KEY=                     # For Qdrant Cloud
AI_DOCS__QDRANT__DEFAULT_COLLECTION=documentation
AI_DOCS__QDRANT__GRPC_PORT=6334               # For high-performance gRPC
AI_DOCS__QDRANT__USE_GRPC=false               # Enable gRPC instead of HTTP

# Firecrawl Settings (when using Firecrawl provider)
AI_DOCS__FIRECRAWL__API_KEY=fc-your-firecrawl-api-key-here
AI_DOCS__FIRECRAWL__API_BASE=https://api.firecrawl.dev

# Security Configuration
AI_DOCS__SECURITY__MAX_QUERY_LENGTH=1000
AI_DOCS__SECURITY__MAX_URL_LENGTH=2048
AI_DOCS__SECURITY__RATE_LIMIT_REQUESTS_PER_MINUTE=60
AI_DOCS__SECURITY__ALLOWED_DOMAINS=["*"]      # JSON array of allowed domains
AI_DOCS__SECURITY__REQUIRE_API_KEYS=true
AI_DOCS__SECURITY__ENABLE_RATE_LIMITING=true

# Directory Paths
AI_DOCS__DATA_DIR=./data                      # Persistent data storage
AI_DOCS__CACHE_DIR=./cache                    # Temporary cache files
AI_DOCS__LOGS_DIR=./logs                      # Application logs

# HyDE (Hypothetical Document Embeddings) Configuration
AI_DOCS__HYDE__ENABLED=true
AI_DOCS__HYDE__MODEL=gpt-3.5-turbo
AI_DOCS__HYDE__MAX_TOKENS=150
AI_DOCS__HYDE__TEMPERATURE=0.7
AI_DOCS__HYDE__NUM_GENERATIONS=5            # Number of hypothetical docs to generate
AI_DOCS__HYDE__CACHE_TTL=3600               # HyDE cache TTL in seconds
AI_DOCS__HYDE__PREFETCH_LIMIT=50            # Query API prefetch limit for HyDE
AI_DOCS__HYDE__QUERY_WEIGHT=0.3             # Weight for original query (vs 0.7 for HyDE)

# Chunking Strategy Configuration
AI_DOCS__CHUNKING__STRATEGY=enhanced           # basic, enhanced, or ast
AI_DOCS__CHUNKING__MAX_CHUNK_SIZE=1600
AI_DOCS__CHUNKING__MIN_CHUNK_SIZE=200
AI_DOCS__CHUNKING__OVERLAP=200

# Batch Processing
AI_DOCS__BATCH__EMBEDDING_BATCH_SIZE=100
AI_DOCS__BATCH__CRAWL_BATCH_SIZE=50
AI_DOCS__BATCH__ENABLE_PROGRESS_BAR=true

# ========== Browser Automation Configuration ==========
# Used for complex scraping scenarios requiring JavaScript execution

# Browser Automation Hierarchy Settings
AI_DOCS__BROWSER__DEFAULT_TOOL=crawl4ai      # crawl4ai, stagehand, playwright
AI_DOCS__BROWSER__ENABLE_FALLBACK=true       # Enable automatic fallback
AI_DOCS__BROWSER__HEADLESS=true              # Run browsers in headless mode
AI_DOCS__BROWSER__TIMEOUT=30000              # Page timeout in milliseconds

# Stagehand AI Configuration (for complex dynamic content)
AI_DOCS__STAGEHAND__MODEL=ollama/llama2      # Local LLM model for AI automation
AI_DOCS__STAGEHAND__ENABLE_CACHING=true      # Cache AI decisions
AI_DOCS__STAGEHAND__DEBUG_SCREENSHOTS=false  # Save debug screenshots

# Playwright Configuration (for maximum control)
AI_DOCS__PLAYWRIGHT__BROWSER=chromium        # chromium, firefox, webkit
AI_DOCS__PLAYWRIGHT__VIEWPORT_WIDTH=1920     # Browser viewport width
AI_DOCS__PLAYWRIGHT__VIEWPORT_HEIGHT=1080    # Browser viewport height

# ========== Reranking Configuration ==========
# BGE-reranker-v2-m3 for 10-20% accuracy improvement

AI_DOCS__RERANKING__ENABLED=false            # Enable reranking (opt-in)
AI_DOCS__RERANKING__MODEL=BAAI/bge-reranker-v2-m3
AI_DOCS__RERANKING__TOP_K=20                 # Candidates to rerank
AI_DOCS__RERANKING__CACHE_TTL=3600           # Cache reranked results for 1 hour
AI_DOCS__RERANKING__BATCH_SIZE=32            # Reranking batch size

# ========== Query API Configuration ==========
# Qdrant Query API multi-stage retrieval settings

AI_DOCS__QUERY_API__PREFETCH_LIMIT=100       # Initial prefetch size
AI_DOCS__QUERY_API__HNSW_EF=128              # HNSW search parameter
AI_DOCS__QUERY_API__QUANTIZATION_RESCORE=true
AI_DOCS__QUERY_API__OVERSAMPLING=2.0         # Quantization oversampling

# ========== Crawl4AI Specific Settings ==========
# High-performance web scraping configuration

AI_DOCS__CRAWL4AI__BROWSER_TYPE=chromium     # Browser to use
AI_DOCS__CRAWL4AI__MAX_CONCURRENT=10         # Concurrent pages
AI_DOCS__CRAWL4AI__PAGE_TIMEOUT=30000        # Page load timeout
AI_DOCS__CRAWL4AI__FETCH_TIMEOUT=10000       # Fetch timeout
AI_DOCS__CRAWL4AI__USER_AGENT=AIDocs/1.0     # Custom user agent
AI_DOCS__CRAWL4AI__CACHE_MODE=enabled        # Enable content caching
AI_DOCS__CRAWL4AI__EXTRACTION_STRATEGY=semantic  # Extraction type
AI_DOCS__CRAWL4AI__LLM_PROVIDER=ollama/llama2    # LLM for extraction

# ========== Collection Aliases Configuration ==========
# Production deployment patterns

AI_DOCS__ALIASES__ENABLE_ALIASES=true        # Enable collection aliases
AI_DOCS__ALIASES__ACTIVE_ALIAS=active        # Active collection alias
AI_DOCS__ALIASES__STAGING_ALIAS=staging      # Staging collection alias
AI_DOCS__ALIASES__DEPLOYMENT_STRATEGY=blue_green  # blue_green, canary, ab_test

# ========== Docker Compose Environment Variables ==========
# These are used by docker-compose.yml for Qdrant and DragonflyDB

# Qdrant Performance Settings
QDRANT__SERVICE__HTTP_PORT=6333
QDRANT__SERVICE__GRPC_PORT=6334
QDRANT__LOG_LEVEL=INFO
QDRANT__STORAGE__ON_DISK_PAYLOAD=true
QDRANT__STORAGE__QUANTIZATION__ALWAYS_RAM=true
QDRANT__STORAGE__PERFORMANCE__MAX_SEARCH_THREADS=8

# DragonflyDB Settings
DRAGONFLY_THREADS=8
DRAGONFLY_MEMORY_LIMIT=4gb
DRAGONFLY_SNAPSHOT_INTERVAL=3600

# ========== Testing Environment Variables ==========
# These are used for integration tests

# Enable real integration tests (default: false for safety)
RUN_REAL_INTEGRATION_TESTS=false

# Crawl4AI timeout for tests (milliseconds)
CRAWL4AI_TIMEOUT=30000

# Test API keys (use these exact values for unit tests)
# AI_DOCS__TEST__OPENAI_API_KEY=sk-test-mock-key-for-testing-only
# AI_DOCS__TEST__FIRECRAWL_API_KEY=fc-test-mock-key-for-testing-only