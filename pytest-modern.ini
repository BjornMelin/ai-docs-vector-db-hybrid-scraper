[pytest]
# Modern Testing Configuration - 2025 Best Practices
# This configuration focuses on AI/ML testing with modern pytest patterns

# Test discovery and collection
testpaths = tests
python_files = test_*.py *_test.py
python_functions = test_*
python_classes = Test* *Test *Tests

# Exclude problematic directories to avoid import issues
norecursedirs = 
    .git 
    .tox 
    dist 
    build 
    *.egg 
    .venv 
    __pycache__ 
    .mypy_cache 
    .pytest_cache 
    .ruff_cache
    .hypothesis

# Modern output formatting optimized for AI/ML testing
addopts = 
    --tb=short
    --strict-markers
    --strict-config
    --disable-warnings
    --no-header
    -ra
    --maxfail=10
    --durations=10
    --showlocals
    --import-mode=importlib
    # Performance optimizations
    --disable-socket
    --allow-hosts=localhost,127.0.0.1,::1,httpbin.org,example.com
    # AI/ML specific settings
    --hypothesis-show-statistics
    --hypothesis-verbosity=normal

# Marker definitions for AI/ML testing
markers =
    # AI/ML specific markers
    ai: marks tests as AI/ML system tests
    embedding: marks tests as embedding-related tests
    vector_db: marks tests as vector database tests
    rag: marks tests as RAG (Retrieval-Augmented Generation) tests
    llm: marks tests as large language model tests
    ml_model: marks tests as machine learning model tests
    
    # Performance categories
    performance_critical: marks tests as performance-critical
    memory_test: marks tests as memory usage tests
    cpu_test: marks tests as CPU usage tests
    throughput: marks tests as throughput tests
    latency: marks tests as latency tests
    scalability: marks tests as scalability tests
    
    # Speed-based categories
    slow: marks tests as slow running (> 5 seconds)
    fast: marks tests as fast running (< 1 second)
    
    # Functional categories
    unit: marks tests as unit tests
    integration: marks tests as integration tests
    performance: marks tests as performance/benchmark tests
    e2e: marks tests as end-to-end tests
    contract: marks tests as contract tests
    property_based: marks tests as property-based tests using Hypothesis
    
    # Infrastructure categories
    browser: marks tests requiring browser automation
    network: marks tests requiring network access
    database: marks tests requiring database connection
    
    # Security categories
    security: marks tests as security tests
    vulnerability_scan: marks tests as vulnerability scan tests
    penetration_test: marks tests as penetration tests
    owasp: marks tests as OWASP compliance tests
    input_validation: marks tests as input validation tests
    authentication: marks tests as authentication tests
    authorization: marks tests as authorization tests
    
    # Platform categories
    windows: marks tests that should only run on Windows
    macos: marks tests that should only run on macOS
    linux: marks tests that should only run on Linux
    unix: marks tests that should run on Unix-like systems
    
    # Environment categories
    ci_only: marks tests that should only run in CI
    local_only: marks tests that should only run locally
    
    # Test quality markers
    hypothesis: marks property-based tests using Hypothesis
    asyncio: marks async tests
    benchmark: marks benchmark tests

# Async test configuration with optimized settings
asyncio_mode = auto
asyncio_default_fixture_loop_scope = function

# Timeout settings optimized for AI/ML workloads
# Note: Longer timeouts for AI operations that may take time
timeout = 300
timeout_method = thread
timeout_func_only = true

# Logging configuration optimized for debugging
log_cli = false
log_cli_level = WARNING
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s (%(filename)s:%(lineno)d)
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Warning filters optimized for AI/ML dependencies
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:.*playwright.*
    ignore::UserWarning:.*fastembed.*
    ignore::UserWarning:.*hypothesis.*
    ignore::ResourceWarning
    ignore::pytest.PytestUnraisableExceptionWarning
    error::pytest.PytestUnhandledThreadExceptionWarning
    # Ignore common AI/ML library warnings
    ignore::FutureWarning:.*numpy.*
    ignore::FutureWarning:.*torch.*
    ignore::FutureWarning:.*transformers.*
    ignore::UserWarning:.*torch.*
    ignore::UserWarning:.*qdrant.*
    ignore::UserWarning:.*openai.*

# Hypothesis configuration for property-based testing
hypothesis-show-statistics = true
hypothesis-verbosity = normal
hypothesis-seed = 42

# Doctests configuration
doctest_optionflags = NORMALIZE_WHITESPACE IGNORE_EXCEPTION_DETAIL ELLIPSIS

# Test discovery optimization
consider_namespace_packages = true

# Console output settings optimized for AI/ML testing
console_output_style = progress

# Custom test collection settings for AI/ML tests
collect_ignore = [
    "setup.py",
    "conftest.py",
]

# Minimum version requirements
minversion = 8.0

# Additional pytest plugins for AI/ML testing
# Note: These should be installed separately if needed
# addopts = --hypothesis-profile=dev
required_plugins = 
    pytest-asyncio>=0.24.0
    pytest-mock>=3.14.0
    pytest-timeout>=2.3.0
    hypothesis>=6.135.0