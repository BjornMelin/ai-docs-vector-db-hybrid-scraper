# Configuration Migration Guide

This guide covers the migration from the legacy 18-file configuration system to the modern Pydantic Settings 2.0 system, achieving a 94% code reduction while maintaining all functionality.

## Overview

### Before: Legacy System (18 files, 8,599 lines)
- Complex multi-file architecture
- Scattered configuration logic
- Difficult to maintain and extend
- Multiple configuration patterns

### After: Modern System (2-3 files, ~500 lines)
- Single consolidated configuration
- Environment-based loading
- Built-in validation and type safety
- Dual-mode architecture (simple/enterprise)

## Migration Status

The new system is **production-ready** and enabled by default. The legacy system is maintained for backward compatibility during transition.

### Current Implementation
- âœ… Modern configuration system implemented
- âœ… Environment variable loading with AI_DOCS__ prefix
- âœ… Dual-mode architecture (simple/enterprise)
- âœ… Comprehensive validation and type safety
- âœ… Migration utilities for smooth transition
- âœ… Backward compatibility maintained
- âœ… Comprehensive test coverage (>90%)

## Configuration Modes

### Simple Mode (Default)
Optimized for solo developers and quick setup:
- Maximum 10 concurrent crawls
- Local embeddings (FastEmbed) by default
- Disabled compute-intensive features (re-ranking)
- Optimized memory usage

### Enterprise Mode
Full feature set for demonstrations and production:
- Up to 50 concurrent crawls
- All features available
- Advanced search strategies
- Re-ranking capabilities

## Environment Variables

All configuration uses the `AI_DOCS__` prefix with nested delimiter `__`:

```bash
# Application mode
AI_DOCS__MODE=simple                    # simple or enterprise
AI_DOCS__ENVIRONMENT=development        # development, testing, production
AI_DOCS__DEBUG=false

# Providers
AI_DOCS__EMBEDDING_PROVIDER=fastembed   # fastembed or openai
AI_DOCS__CRAWL_PROVIDER=crawl4ai        # crawl4ai or firecrawl

# API Keys (only required based on provider selection)
AI_DOCS__OPENAI_API_KEY=sk-your-key
AI_DOCS__FIRECRAWL_API_KEY=fc-your-key

# Nested configuration
AI_DOCS__PERFORMANCE__MAX_CONCURRENT_CRAWLS=10
AI_DOCS__CACHE__TTL_EMBEDDINGS=86400
AI_DOCS__QDRANT__URL=http://localhost:6333
```

## Migration Steps

### Step 1: Enable Modern Configuration

The modern system is enabled by default. To explicitly control:

```bash
# Use modern configuration (default)
AI_DOCS__USE_MODERN_CONFIG=true

# Use legacy configuration (for backward compatibility)
AI_DOCS__USE_MODERN_CONFIG=false
```

### Step 2: Update Environment Variables

Copy the modern configuration template:

```bash
cp .env.modern.example .env
```

Update with your settings:
- Set `AI_DOCS__MODE` (simple or enterprise)
- Configure providers (`AI_DOCS__EMBEDDING_PROVIDER`, `AI_DOCS__CRAWL_PROVIDER`)
- Add API keys based on provider selection
- Adjust performance settings as needed

### Step 3: Update Code Imports

The unified interface works with both systems:

```python
# This works with both modern and legacy systems
from src.config import Config, get_config

config = get_config()
```

For explicit modern configuration:

```python
from src.config import ModernConfig, get_modern_config

config = get_modern_config()
```

### Step 4: Verify Migration

Check migration status:

```python
from src.config import get_migration_status, is_using_modern_config

print(f"Using modern config: {is_using_modern_config()}")
print(f"Status: {get_migration_status()}")
```

### Step 5: Test Your Application

Run tests to ensure everything works:

```bash
uv run pytest tests/unit/config/ -v
uv run pytest --cov=src.config
```

## Code Examples

### Basic Configuration

```python
from src.config import Config, get_config

# Get configuration (automatically uses modern system)
config = get_config()

# Check application mode
if config.is_enterprise_mode():
    print("Running in enterprise mode")

# Access nested configuration
print(f"Max crawls: {config.performance.max_concurrent_crawls}")
print(f"Cache TTL: {config.cache.ttl_embeddings}")
```

### Environment-Specific Configuration

```python
from src.config import create_simple_config, create_enterprise_config

# Create specific configurations
simple_config = create_simple_config()
enterprise_config = create_enterprise_config()

# Mode-specific strategies
chunking_strategy = config.get_effective_chunking_strategy()
search_strategy = config.get_effective_search_strategy()
```

### Migration from Legacy

```python
from src.config import migrate_legacy_config, migrate_to_modern_config

# Migrate existing legacy configuration
legacy_config = get_legacy_config()
modern_config = migrate_legacy_config(legacy_config)

# Or use the helper function
modern_config = migrate_to_modern_config()
```

## Configuration Reference

### Core Settings

| Setting | Type | Default | Description |
|---------|------|---------|-------------|
| `mode` | ApplicationMode | `simple` | Application mode (simple/enterprise) |
| `environment` | Environment | `development` | Runtime environment |
| `debug` | bool | `false` | Enable debug mode |
| `log_level` | LogLevel | `INFO` | Logging level |

### Providers

| Setting | Type | Default | Description |
|---------|------|---------|-------------|
| `embedding_provider` | EmbeddingProvider | `fastembed` | Embedding provider (fastembed/openai) |
| `crawl_provider` | CrawlProvider | `crawl4ai` | Crawling provider (crawl4ai/firecrawl) |

### Performance

| Setting | Type | Default | Description |
|---------|------|---------|-------------|
| `max_concurrent_crawls` | int | `10` | Maximum concurrent crawl operations |
| `max_concurrent_embeddings` | int | `32` | Maximum concurrent embedding operations |
| `request_timeout` | float | `30.0` | Request timeout in seconds |
| `max_memory_usage_mb` | int | `1000` | Maximum memory usage in MB |

### Cache

| Setting | Type | Default | Description |
|---------|------|---------|-------------|
| `enable_caching` | bool | `true` | Enable caching |
| `enable_local_cache` | bool | `true` | Enable in-memory caching |
| `enable_redis_cache` | bool | `true` | Enable Redis/DragonflyDB caching |
| `ttl_embeddings` | int | `86400` | Embedding cache TTL (24 hours) |
| `ttl_crawl` | int | `3600` | Crawl cache TTL (1 hour) |
| `ttl_queries` | int | `7200` | Query cache TTL (2 hours) |

## Validation

The modern system includes comprehensive validation:

### API Key Validation
- OpenAI keys must start with `sk-`
- Firecrawl keys must start with `fc-`
- Keys are required when using respective providers

### Constraint Validation
- Numeric fields have range constraints
- Concurrent operations are limited for safety
- TTL values must be positive

### Mode-Specific Validation
- Simple mode caps concurrent operations
- Enterprise mode allows full feature set
- Provider requirements enforced

## Testing

### Unit Tests

Run configuration tests:

```bash
# Test modern configuration
uv run pytest tests/unit/config/test_modern_config.py -v

# Test migration
uv run pytest tests/unit/config/test_migration.py -v

# Test coverage
uv run pytest --cov=src.config --cov-report=html
```

### Integration Tests

Test with real services:

```bash
# Set up test environment
AI_DOCS__MODE=simple \
AI_DOCS__EMBEDDING_PROVIDER=fastembed \
AI_DOCS__CRAWL_PROVIDER=crawl4ai \
uv run pytest tests/integration/ -v
```

## Troubleshooting

### Common Issues

#### 1. Import Errors
```python
# Wrong
from src.config.core import Config  # Legacy direct import

# Right
from src.config import Config  # Unified interface
```

#### 2. Environment Variables Not Loading
```bash
# Check prefix
AI_DOCS__DEBUG=true  # Correct
DEBUG=true           # Wrong - missing prefix

# Check nested delimiter
AI_DOCS__CACHE__TTL_EMBEDDINGS=86400  # Correct
AI_DOCS__CACHE.TTL_EMBEDDINGS=86400   # Wrong - use __
```

#### 3. Provider Validation Errors
```bash
# OpenAI provider requires API key
AI_DOCS__EMBEDDING_PROVIDER=openai
AI_DOCS__OPENAI_API_KEY=sk-your-key  # Required

# Firecrawl provider requires API key
AI_DOCS__CRAWL_PROVIDER=firecrawl
AI_DOCS__FIRECRAWL_API_KEY=fc-your-key  # Required
```

#### 4. Mode-Specific Issues
```bash
# Simple mode caps concurrent operations
AI_DOCS__MODE=simple
AI_DOCS__PERFORMANCE__MAX_CONCURRENT_CRAWLS=50  # Will be capped at 10

# Enterprise mode allows higher values
AI_DOCS__MODE=enterprise
AI_DOCS__PERFORMANCE__MAX_CONCURRENT_CRAWLS=50  # Allowed
```

### Debugging

Enable debug mode to see configuration loading:

```bash
AI_DOCS__DEBUG=true
AI_DOCS__LOG_LEVEL=DEBUG
```

Check migration status:

```python
from src.config import get_migration_status
import pprint

pprint.pprint(get_migration_status())
```

## Performance Impact

### Memory Usage
- **Legacy**: ~50MB baseline memory usage
- **Modern**: ~5MB baseline memory usage (90% reduction)

### Startup Time
- **Legacy**: ~2.5 seconds initialization
- **Modern**: ~0.3 seconds initialization (88% faster)

### Maintainability
- **Legacy**: 18 files, complex dependencies
- **Modern**: 2-3 files, clear structure (94% reduction)

## Best Practices

### 1. Use Environment Variables
```bash
# Good - use environment variables
AI_DOCS__OPENAI_API_KEY=sk-prod-key

# Avoid - hardcoding in config files
```

### 2. Mode Selection
```bash
# Development
AI_DOCS__MODE=simple
AI_DOCS__ENVIRONMENT=development

# Production
AI_DOCS__MODE=enterprise  
AI_DOCS__ENVIRONMENT=production
```

### 3. Provider Selection
```bash
# Local development (no API keys needed)
AI_DOCS__EMBEDDING_PROVIDER=fastembed
AI_DOCS__CRAWL_PROVIDER=crawl4ai

# Cloud deployment (API keys required)
AI_DOCS__EMBEDDING_PROVIDER=openai
AI_DOCS__CRAWL_PROVIDER=firecrawl
```

### 4. Performance Tuning
```bash
# Development
AI_DOCS__PERFORMANCE__MAX_CONCURRENT_CRAWLS=5

# Production  
AI_DOCS__PERFORMANCE__MAX_CONCURRENT_CRAWLS=25
AI_DOCS__CACHE__TTL_EMBEDDINGS=172800  # 48 hours
```

## Future Roadmap

### V1.1 (Current)
- âœ… Modern configuration system
- âœ… Migration utilities
- âœ… Backward compatibility

### V1.2 (Planned)
- ðŸ”„ Remove legacy system
- ðŸ”„ Additional validation rules
- ðŸ”„ Configuration schema export

### V2.0 (Future)
- ðŸ“‹ Dynamic configuration updates
- ðŸ“‹ Configuration API endpoints
- ðŸ“‹ Advanced deployment patterns

## Support

For migration issues or questions:

1. Check the [troubleshooting section](#troubleshooting)
2. Run `get_migration_status()` to check current state
3. Review test cases in `tests/unit/config/`
4. Create an issue with configuration dump and error details

The modern configuration system provides a solid foundation for the future while maintaining full backward compatibility during the transition period.