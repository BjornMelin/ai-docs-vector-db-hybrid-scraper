# SOTA 2025 AI Documentation Vector Database Hybrid Scraper Dependencies
# Research-backed optimal embedding pipeline with hybrid search capabilities
# Using uv for ultra-fast package management with Python 3.13+

# Core web crawling and scraping
crawl4ai[all]>=0.6.0
aiohttp>=3.8.0
asyncio-throttle>=1.0.2

# SOTA 2025 Vector database and embeddings (research-backed stack)
qdrant-client[fastembed]>=1.7.0  # Hybrid search support with FastEmbed integration
openai>=1.0.0
fastembed>=0.2.5  # 50% faster than PyTorch, better than OpenAI ada-002
FlagEmbedding>=1.3.0  # BGE-reranker-v2-m3 for 10-20% accuracy improvement
firecrawl-py>=0.0.8  # Premium extraction features (optional)

# Data processing and analysis
pandas>=2.0.0
numpy>=1.24.0

# Utilities and logging
python-dotenv>=1.0.0
colorlog>=6.7.0
tqdm>=4.65.0

# Enhanced performance with latest versions
playwright>=1.40.0
httpx>=0.25.0

# Development and testing
pytest>=7.4.0
pytest-asyncio>=0.21.0
black>=23.0.0
ruff>=0.7.0

# Additional dependencies for modern Python features
pydantic>=2.0.0
click>=8.1.0
rich>=13.0.0

# SOTA 2025 Installation Notes:
# =============================
# 
# 1. Core installation (required):
#    uv add crawl4ai[all] "qdrant-client[fastembed]" openai fastembed FlagEmbedding
#
# 2. Premium features (optional):
#    uv add firecrawl-py
#    export FIRECRAWL_API_KEY="your_key"
#
# 3. Expected performance gains:
#    - 50% faster embedding generation (FastEmbed vs PyTorch)
#    - 83-99% storage cost reduction (quantization + Matryoshka)
#    - 8-15% better retrieval accuracy (hybrid search)
#    - 10-20% additional improvement (BGE reranking on top of hybrid)
#    - 5x lower API costs (text-embedding-3-small vs ada-002)
#
# 4. Research-backed configuration:
#    - Chunk size: 1600 characters (optimal 400-600 tokens)
#    - Models: text-embedding-3-small, NV-Embed-v2, BGE-small-en-v1.5
#    - Search: Hybrid dense+sparse with RRF ranking
