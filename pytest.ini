[pytest]
# Test Infrastructure Modernization - Optimized Configuration

# Core collection settings
testpaths = tests
python_files = test_*.py
python_functions = test_*
python_classes = Test* *Test *Tests

# Output formatting for fast feedback
addopts = 
    --tb=short
    --strict-markers
    --disable-warnings
    --no-header
    -ra
    --maxfail=10
    --durations=10

# Marker definitions for test categorization
markers =
    # Speed-based categories
    slow: marks tests as slow running (> 5 seconds)
    fast: marks tests as fast running (< 1 second)
    
    # Functional categories
    unit: marks tests as unit tests
    integration: marks tests as integration tests
    performance: marks tests as performance/benchmark tests
    e2e: marks tests as end-to-end tests
    contract: marks tests as contract tests
    consumer_driven: marks tests as consumer-driven contract tests
    deployment: marks tests related to deployment
    pipeline: marks tests related to deployment pipeline
    infrastructure: marks tests related to infrastructure
    blue_green: marks tests related to blue-green deployment
    security: marks tests as security tests
    disaster_recovery: marks tests related to disaster recovery
    mcp: marks tests related to Model Context Protocol
    browser_monitoring: marks tests for browser automation monitoring
    database_pooling: marks tests for database connection pooling
    environment: marks tests related to environment configuration
    
    # Environment categories
    browser: marks tests requiring browser automation
    network: marks tests requiring network access
    database: marks tests requiring database connection
    
    # Platform categories
    windows: marks tests that should only run on Windows
    macos: marks tests that should only run on macOS
    linux: marks tests that should only run on Linux
    unix: marks tests that should run on Unix-like systems
    
    # Execution context
    ci_only: marks tests that should only run in CI
    local_only: marks tests that should only run locally
    
    # Test quality
    hypothesis: marks property-based tests using Hypothesis
    asyncio: marks async tests
    benchmark: marks benchmark tests

# Timeout settings (can be overridden by platform-specific configs)
timeout = 120

# Parallel execution
# Note: -n auto will be added by test runner scripts for parallel execution

# Async test configuration  
asyncio_mode = auto
asyncio_default_fixture_loop_scope = function

# Logging during tests
log_cli = false
log_cli_level = WARNING
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s (%(filename)s:%(lineno)d)
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Warnings filter
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:.*playwright.*
    ignore::UserWarning:.*fastembed.*
    ignore::ResourceWarning