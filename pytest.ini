[pytest]
# Test Infrastructure Configuration - Optimized for 2025

# Core collection settings
testpaths = tests
python_files = test_*.py
python_functions = test_*
python_classes = Test* *Test *Tests

# Collection optimization
norecursedirs = .git .tox dist build *.egg .venv __pycache__ .mypy_cache .pytest_cache .ruff_cache node_modules

# Output formatting - CI-friendly with proper verbosity
addopts = 
    --tb=short
    --strict-markers
    --strict-config
    --disable-warnings
    -ra
    --maxfail=10
    --durations=20
    --showlocals
    --cov=src
    --cov-report=term-missing:skip-covered
    --cov-report=html
    --cov-report=xml
    --cov-fail-under=80
    --timeout=300
    --timeout-method=thread
    -p no:randomly
    --dist=loadscope
    --numprocesses=auto

# Test execution settings for CI
minversion = 7.0
required_plugins = 
    pytest-asyncio>=0.21.0
    pytest-cov>=4.0.0
    pytest-timeout>=2.1.0
    pytest-xdist>=3.0.0
    pytest-env>=0.8.0

# Timeout configuration
timeout = 300
timeout_method = thread
timeout_func_only = true

# Coverage configuration
[coverage:run]
source = src
parallel = true
concurrency = multiprocessing,thread
omit = 
    */tests/*
    */test_*
    */__pycache__/*
    */site-packages/*

[coverage:report]
precision = 2
show_missing = true
skip_covered = true
skip_empty = true
exclude_lines = 
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:
    @abstract
    @abstractmethod

# CI-specific environment variables (set via shell or CI environment)
    PYTHONDONTWRITEBYTECODE=1
    PYTHONUNBUFFERED=1

# Core markers - organized and de-duplicated
markers =
    # Speed categories
    fast: marks tests as fast running (< 1 second)
    slow: marks tests as slow running (> 5 seconds)
    
    # Test types
    unit: marks tests as unit tests
    integration: marks tests as integration tests
    e2e: marks tests as end-to-end tests
    performance: marks tests as performance/benchmark tests
    contract: marks tests as contract tests
    benchmark: marks tests as benchmark tests
    smoke: marks tests as smoke tests
    
    # AI/ML specific
    ai: marks tests as AI/ML specific
    embedding: marks tests as embedding-related
    vector_db: marks tests as vector database related
    rag: marks tests as RAG system related
    # Deployment markers
    deployment: marks tests as deployment-related
    blue_green: marks tests as blue-green deployment tests
    disaster_recovery: marks tests as disaster recovery tests
    post_deployment: marks tests as post-deployment validation
    performance_critical: marks tests that are performance critical
    injection: marks tests for dependency injection
    browser_monitoring: marks tests for browser monitoring
    database_pooling: marks tests for database connection pooling
    reporting: marks tests for reporting functionality
    
    # Security
    security: marks tests as security tests
    vulnerability: marks tests as vulnerability tests
    auth: marks tests as authentication tests
    penetration: marks tests as penetration tests
    authentication: marks tests as authentication tests
    authorization: marks tests as authorization tests
    owasp: marks tests as OWASP compliance tests
    encryption: marks tests as encryption tests
    input_validation: marks tests as input validation tests
    
    # Infrastructure
    browser: marks tests requiring browser automation
    network: marks tests requiring network access
    database: marks tests requiring database connection
    mcp: marks tests related to Model Context Protocol
    deployment: marks tests as deployment tests
    environment: marks tests as environment validation tests
    infrastructure: marks tests as infrastructure validation tests
    rate_limit: marks tests as rate limiting tests
    pipeline: marks tests as CI/CD pipeline tests
    
    # Monitoring and operations
    browser_monitoring: marks tests for browser automation monitoring
    database_pooling: marks tests for database connection pooling
    performance_critical: marks tests as performance critical tests
    
    # Security specific
    injection: marks tests for injection prevention
    
    # Platform
    windows: marks tests that should only run on Windows
    macos: marks tests that should only run on macOS
    linux: marks tests that should only run on Linux
    unix: marks tests that should run on Unix-like systems
    
    # Environment
    ci_only: marks tests that should only run in CI
    local_only: marks tests that should only run locally
    
    # Load testing
    load: marks tests as load tests
    stress: marks tests as stress tests
    chaos: marks tests as chaos engineering tests
    
    # Accessibility
    accessibility: marks tests as accessibility tests
    a11y: marks tests as general accessibility tests
    wcag: marks tests as WCAG compliance tests
    
    # Test framework
    asyncio: marks async tests
    hypothesis: marks property-based tests using Hypothesis
    property: marks tests as property-based tests

# Async configuration
asyncio_mode = auto
asyncio_default_fixture_loop_scope = function

# Logging
log_cli = false
log_cli_level = WARNING
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s (%(filename)s:%(lineno)d)
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Warnings filter
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:.*playwright.*
    ignore::UserWarning:.*fastembed.*
    ignore::ResourceWarning
    ignore::pytest.PytestUnraisableExceptionWarning
    error::pytest.PytestUnhandledThreadExceptionWarning

# Test discovery
consider_namespace_packages = true
console_output_style = progress
doctest_optionflags = NORMALIZE_WHITESPACE IGNORE_EXCEPTION_DETAIL ELLIPSIS